{
	"data": [
		{
	      	"runId": "runs_1_x",
			"tagKey": "00_train/reward_mean",
			"type": "scalar",
			"stats": {
	                "minStep": 1,
	                "maxStep": 6,
	                "count": 6,
	                "lastValue": 64.0,
	                "updatedAt": 1762833398250,
	                "mean": 45.0,
	                "variance": 725.0
	            },
			"encodedSteps": "AQAAAAIAAAADAAAABAAAAAUAAAAGAAAA",
			"encodedValues": "AAAgQQAAgEAAAIBCAACAQgAAgEIAAIBC"
		},
		{
	      	"runId": "runs_1_x",
			"tagKey": "01_train/loss_q_value",
			"type": "scalar",
			"stats": {
	                "minStep": 1,
	                "maxStep": 6,
	                "count": 6,
	                "lastValue": 64.0,
	                "updatedAt": 1762833398250,
	                "mean": 45.0,
	                "variance": 725.0
	            },
			"encodedSteps": "AQAAAAIAAAADAAAABAAAAAUAAAAGAAAA",
			"encodedValues": "AAAgQQAAgEAAAIBCAACAQgAAgEIAAIBC"
		},
		{
	      	"runId": "runs_2_s",
			"tagKey": "32_agent_dqn_base/03_epsilon",
			"type": "scalar",
			"stats": {
	                "minStep": 1,
	                "maxStep": 6,
	                "count": 6,
	                "lastValue": 64.0,
	                "updatedAt": 1762833398250,
	                "mean": 45.0,
	                "variance": 725.0
	            },
			"encodedSteps": "AQAAAAIAAAADAAAABAAAAAUAAAAGAAAA",
			"encodedValues": "AAAgQQAAgEAAAIBCAACAQgAAgEIAAIBC"
		}
	]
}
